# Naive Bayes για Δυαδική Ταξινόμηση Κειμένου: Υλοποίηση από το Μηδέν και Σύγκριση με scikit-learn
## Αλγόριθμοι Μηχανικής Μάθησης
*Τεχνητή Νοημοσύνη, Οικονομικό Πανεπιστήμιο Αθηνών Χειμερινό εξάμινο 2024-2025*

Μελέτη του αλγορίθμου Naive Bayes για δυαδική ταξινόμηση κειμένου 
χρησιμοποιώντας την πολυμεταβλητή παραλλαγή Bernoulli, δηλαδή λαμβάνεται υπόψη μόνο η παρουσία ή απουσία μιας λέξης σε μια κριτική και όχι ο αριθμός των φορών που εμφανίζεται.

Ο αλγόριθμος υλοποιήθηκε δύο φορές: μία με έτοιμες συναρτήσεις από τη βιβλιοθήκη scikit-learn και μία δική μου υλοποίηση χωρίς εξωτερικές βιβλιοθήκες. 
Η εφαρμογή έγινε στο σύνολο δεδομένων IMDB για την κατάταξη κριτικών ταινιών 
σε θετικές ή αρνητικές.  

Αποτελέσματα αξιολόγησης των υλοποιήσεων:

## Α. Με δική μου υλοποίηση του Naive Bayes
![my implementation](myimplementation.png)

| Metric    | Class 0  | Class 1  | Micro-averaged | Macro-averaged |
|-----------|---------:|---------:|---------------:|---------------:|
| Precision | 0.861747 | 0.827768 | 0.84392        | 0.844757       |
| Recall    | 0.819280 | 0.868560 | 0.84392        | 0.843920       |
| F1-Score  | 0.839977 | 0.847673 | 0.84392        | 0.843825       |


## B. Με έτοιμες υλοποιήσεις από τη βιβλιοθήκη Scikit-learn
![sklearn](sklearn.png)

| Metric    | Class 0  | Class 1  | Micro-averaged | Macro-averaged |
|-----------|---------:|---------:|---------------:|---------------:|
| Precision | 0.841918 | 0.850673 | 0.84624        | 0.846295       |
| Recall    | 0.852560 | 0.839920 | 0.84624        | 0.846240       |
| F1-Score  | 0.847206 | 0.845262 | 0.84624        | 0.846234       |

<br>
<br>
Λεπτομέριες για τις μεθόδους αξιολόγησης:

**Καμπύλες μάθησης** που δείχνουν αποτελέσματα ακρίβειας (precision) και ανάκλησης (recall) για μία από τις δύο κατηγορίες, στα δεδομένα εκπαίδευσης (training data, όσα έχουν χρησιμοποιηθεί σε κάθε επανάληψη) και στο σύνολο επικύρωσης (validation set, σταθερό σε όλες τις επαναλήψεις), συναρτήσει του πλήθους των παραδειγμάτων εκπαίδευσης που χρησιμοποιούνται σε κάθε επανάληψη του πειράματος.

**Πίνακες αποτελεσμάτων** με ακρίβεια (precision), ανάκληση (recall) και F1 για κάθε μία από τις δύο κατηγορίες, καθώς και μέσους όρους (micro και macro-averaged), στα δεδομένα αξιολόγησης (test data), όταν χρησιμοποιούνται όλα τα δεδομένα εκπαίδευσης.

Κάθε κείμενο κριτικής παριστάνεται ως ένα διάνυσμα ιδιοτήτων με τιμές 0 ή 1, οι οποίες δείχνουν ποιες λέξεις ενός λεξιλογίου περιέχονται στο κείμενο.  
Το λεξιλόγιο κατασκευάζεται παραλείποντας αρχικά τις n πιο συχνές και τις k πιο σπάνιες λέξεις των κειμένων εκπαίδευσης, θεωρώντας ότι η συχνότητα μιας λέξης ισούται με το πλήθος των κειμένων εκπαίδευσης στα οποία εμφανίζεται. Από τις λέξεις των δεδομένων εκπαίδευσης που απομένουν, επιλέγονται ως λέξεις του λεξιλογίου οι m λέξεις με το υψηλότερο πληροφοριακό κέρδος (information gain).

Το λεξιλόγιο είναι το ίδιο και για τις δύο υλοποιήσεις του αλγορίθμου μάθησης.

**Σημαντικό:** Για να τρέξει ο κώδικας τοπικά απαιτούνται οι σωστές εκδόσεις των πακέτων. Στο αρχείο `instructions` περιγράφεται τι χρειάζεται.

**Εκτέλεση του κώδικα:**

py set.py → Δημιουργία του τελικού λεξιλογίου στο αρχείο vocab.txt
py 1.py → Χρήση της δικής μου υλοποίησης
py 2.py → Χρήση της έτοιμης υλοποίησης

**Τιμές υπερπαραμέτρων:**

Μέγεθος λεξιλογίου:  
m = 456 (m_threshold = 0.0016, δηλαδή διαγράφηκαν όσες λέξεις είχαν μικρότερο information gain από 0.0016)

Κατώφλι συχνότητας εμφάνισης λέξεων (σπάνιες):  
k = 34, διαγράφηκαν όσες λέξεις εμφανίζονταν λιγότερο από 34 φορές.

Κατώφλι συχνότητας εμφάνισης λέξεων (συχνές):  
n = 100, διαγράφηκαν οι 100 συχνότερα εμφανιζόμενες λέξεις.

Οι υπερπαράμετροι αυτές επιλέχθηκαν από ένα σύνολο προτεινόμενων τιμών και τελικά χρησιμοποιήθηκαν εκείνες που απέδιδαν καλύτερα στην πράξη.

## Παραλείψεις
Οι υπερπαράμετροι δεν υπολογίστηκαν με τη μέθοδο των δεδομένων ανάπτυξης (development data), αλλά «με το μάτι».

## Συμπέρασμα
Και οι δύο υλοποιήσεις του αλγορίθμου Naive Bayes παρουσιάζουν καλή απόδοση
για την δυαδική ταξινόμηση κειμένου.
Οι καμπύλες δείχνουν να συγκλίνουν μεταξύ εκπαίδευσης και επικύρωσης, το οποίο δείχνει
καλή γενίκευση του μοντέλου. 

Η υλοποίηση με τη βιβλιοθήκη scikit-learn έχει ελαφρώς καλύτερα αποτελέσματα, η διαφορά είναι πολύ μικρή και πρακτικά αμελητέα.
Συνεπώς η υλοποίηση από το μηδέν μπορεί να θεωρηθεί αποδεκτή και συγκρίσιμη με την έτοιμη υλοποίηση.

Τέλος, η σταθεροποίηση των επιδόσεων με την αύξηση των δεδομένων δείχνει ότι η συγκεκριμένη προσέγγιση του Naive Bayes έχει φτάσει στα όρια της και για να
βελτιωθεί περισσότερο απαιτείται διαφορετικό μοντέλο.